<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Xke-kafka by mblanc</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>Xke-kafka</h1>
        <h2></h2>
        <a href="https://github.com/mblanc/xke-kafka" class="button"><small>View project on</small> GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h1>
<a id="installation" class="anchor" href="#installation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Installation</h1>

<h2>
<a id="download-et-installation" class="anchor" href="#download-et-installation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Download et installation</h2>

<p>Télécharger la version  0.8.2.1 de Kafka <a href="http://kafka.apache.org/downloads.html">http://kafka.apache.org/downloads.html</a> 
(Si vous voulez utiliser Scala avec Kafka assurez vous de prendre la version qui correspond à la version de Scala).</p>

<p>Dans un répertoire de travail (ex : ~/xke-kafka) </p>

<p>Extraire la distribution de Kafka</p>

<pre><code>$ tar xzf kafka_2.10-0.8.2.1.tgz
</code></pre>

<p>Créer deux répertoires qui contiendront les logs des différents brokers de Kafka :</p>

<pre><code>$ mkdir log1
$ mkdir log2
</code></pre>

<h3>
<a id="démarrer-zookeeper" class="anchor" href="#d%C3%A9marrer-zookeeper" aria-hidden="true"><span class="octicon octicon-link"></span></a>Démarrer Zookeeper</h3>

<p>Kafka contient sa propre distribution de Zookeeper (pour les tests et les demos, NE PAS UTILISER EN PROD)</p>

<p>Démarrer Zookeeper :</p>

<pre><code>./bin/zookeeper-server-start.sh config/zookeeper.properties &amp;
</code></pre>

<h2>
<a id="démarrer-un-broker" class="anchor" href="#d%C3%A9marrer-un-broker" aria-hidden="true"><span class="octicon octicon-link"></span></a>Démarrer un broker</h2>

<p>Editer le fichier de configuration de Kafka config/server.properties et modifier la valeur de log.dirs :</p>

<pre><code>log.dirs=~/xke-kafka/log1
</code></pre>

<p>Démarrer le broker :</p>

<pre><code>./bin/kafka-server-start.sh config/server.properties &amp;
</code></pre>

<h2>
<a id="démarrer-un-second-broker" class="anchor" href="#d%C3%A9marrer-un-second-broker" aria-hidden="true"><span class="octicon octicon-link"></span></a>Démarrer un second broker</h2>

<p>Copier le fichier de configuration de Kafka</p>

<pre><code>cp config/server.properties config/server2.properties
</code></pre>

<p>Dans la configuration du second broker (config/server2.properties), modifier les valeurs de broker.id, 
port et log.dirs :</p>

<pre><code>broker.id=1
port=9091
log.dirs=~/xke-kafka/log2
</code></pre>

<p>Démarrer le second broker :</p>

<pre><code>./bin/kafka-server-start.sh config/server2.properties &amp;
</code></pre>

<h2>
<a id="créer-une-topic" class="anchor" href="#cr%C3%A9er-une-topic" aria-hidden="true"><span class="octicon octicon-link"></span></a>Créer une topic</h2>

<p>Kafka propose un utilitaire pour la gestion des topics. 
Lancer le pour découvrir ses options : </p>

<pre><code>./bin/kafka-topics.sh
</code></pre>

<p>Puis démarrer la topic first : </p>

<pre><code>./bin/kafka-topics.sh --create \
  --zookeeper localhost:2181 \
  --replication-factor 2 \
  --partitions 2 \
  --topic first
</code></pre>

<p>Verifier les partitions de cette topic :</p>

<pre><code>./bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic first
</code></pre>

<h2>
<a id="valider-la-configuration-avec-le-console-producer-et-le-console-consumer" class="anchor" href="#valider-la-configuration-avec-le-console-producer-et-le-console-consumer" aria-hidden="true"><span class="octicon octicon-link"></span></a>Valider la configuration avec le console-producer et le console-consumer</h2>

<p>Dans un nouveau terminal, créer un producer kafka qui enverra dans la topic tous messages écrits dans la console :</p>

<pre><code>./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic first
</code></pre>

<p>Dans un autre terminal, lancer un consommateur kafka qui affichera dans la console tous les messages d'une topic :</p>

<pre><code>./bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic first --from-beginning
</code></pre>

<p>Vérifier que tout marche bien.</p>

<h1>
<a id="créer-un-producer-kafka" class="anchor" href="#cr%C3%A9er-un-producer-kafka" aria-hidden="true"><span class="octicon octicon-link"></span></a>Créer un Producer Kafka</h1>

<h2>
<a id="old-producers" class="anchor" href="#old-producers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Old producers</h2>

<ul>
<li>Sync -&gt; Safe but slow</li>
<li>Async -&gt; high performance but silent errors</li>
</ul>

<p>pour l'instant on ne l'implémente pas, faire un résumé de l'API et des pros and cons</p>

<h2>
<a id="new-producers" class="anchor" href="#new-producers" aria-hidden="true"><span class="octicon octicon-link"></span></a>New producers</h2>

<ul>
<li>can be use synchronously or asynchronously</li>
<li>both modes can handle errors</li>
<li>bounded memory usage</li>
<li>multi-threaded</li>
</ul>

<p>Faire implémenter un producer, et verifier que ça marche avec le console-consumer</p>

<h1>
<a id="consumer" class="anchor" href="#consumer" aria-hidden="true"><span class="octicon octicon-link"></span></a>Consumer</h1>

<h2>
<a id="high-level-consumer" class="anchor" href="#high-level-consumer" aria-hidden="true"><span class="octicon octicon-link"></span></a>High Level Consumer</h2>

<p>Résumé des concepts et de l'API, pros and cons</p>

<p>Faire implémenter un consumer, et vérifier qu'il recoit les données envoyées par le producer ci-dessus</p>

<h1>
<a id="kafka-par-la-face-nord" class="anchor" href="#kafka-par-la-face-nord" aria-hidden="true"><span class="octicon octicon-link"></span></a>Kafka par la face nord</h1>

<h2>
<a id="notions" class="anchor" href="#notions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Notions</h2>

<p>Petit rappel des notions de base:</p>

<ul>
<li>
<strong>publish/subscribe</strong>: pattern d'architecture qui découple production et consommation. Un émetter poste un message dans un broker. On peut avoir la distribution de ce message de 0 à N listeners connectés. C'est le listener qui choisit ce qu'il reçoit.</li>
<li>
<strong>noeud</strong>: un serveur Kafka.</li>
<li>
<strong>cluster</strong>: un ensemble de noeuds Kafka communicant entre eux pour former un service cohérent. Les noeuds se synchronisent au travers de Zookeeper pour se répartit les données et les réplicats.</li>
<li>
<strong>Zookeeper</strong>: peut être vu que une base de registre distribuée hautement disponible et fortement cohérente. Un des outils incontournables dans les architectures master/master.</li>
<li>
<strong>topic</strong>: un topic est un nom logique regroupant des partitions. On stocke dans un topic des messages du même type, facilitant ainsi la consommation par les listeners. Un topic possède des caractéristiques comme le nombre de partitions, le délai de rétention des messages (Kafka fait de la purge automatique), le facteur de réplication...</li>
<li>
<strong>partition</strong>: une partition peut être vue comme une pile de message. Mais contraitement à une queue, ce n'est pas une FIFO. Les messages sont historisés pendant pour la durée de rétention du topic. Ils ne disparaissent pas à la consommation. L'ordre des messages est seulement garanti au sein d'une partition, pas d'un topic. Il n'y a toujours au plus qu'un noeud Kafka leader sur une partition. Il centralise ainsi toutes les écritures. Deux messages envoyés successivement par un même producteur seront stockés dans le même ordre dans la partition.</li>
<li>
<strong>offset</strong>: ID unique d'un message pour un couple topic/partition. C'est un nombre strictement croissant. C'est le point central de la production/consommation de message dans Kafka</li>
<li>
<strong>producteur</strong>: c'est l'émetteur d'un message. Il peut poster un message dans un topic en choississant spécifiquement une partition ou un au hasard.</li>
<li>
<strong>consommateur</strong>: c'est l'écouteur de messages. Il se connecte à un topic/partition et demande à recevoir des messages. Il existe deux API: HighLevel and SimpleConsumer. La première est très simple à mettre en place mais il y a peu de paramètres de gestion de l'offset. La seconde offre un contrôle total au prix de quelques bouts de code à faire. On peut choisir de consommer des messages depuis le premier offset d'une partition, du dernier pour ne recevoir que les suivants, ou d'un offset arbitraire.</li>
<li>
<strong>groupe de consommateur</strong>: c'est un ensemble fonctionnel de consommateurs. Les partitions dans Kafka sont persistentes. Les messages ne disparaissent pas à la consommation. Pourtant, les consommateurs de messages ne veulent pas forcément traiter tous les messages debuit le début de la partition à chaque redémarrage. Un consommateur peut faire un <em>commit</em> de son dernier offset lu dans Kafka. Au redémarrage, il suffit d'aller chercher cette valeur est de redémarrer la consommation depuis cet offset. Cet offset est au moins unique pour un couple topic/partition. Mais comme plusieurs consommateurs peuvent lire la même partition du même topic en même temps, et à des vitesses différentes, les offsets sont commités pour le triplet (groupe,topic,partittion).</li>
</ul>

<h2>
<a id="les-étapes-pour-créer-un-consommateur" class="anchor" href="#les-%C3%A9tapes-pour-cr%C3%A9er-un-consommateur" aria-hidden="true"><span class="octicon octicon-link"></span></a>Les étapes pour créer un consommateur</h2>

<h3>
<a id="récupération-de-la-configuration-du-cluster-pour-un-topic" class="anchor" href="#r%C3%A9cup%C3%A9ration-de-la-configuration-du-cluster-pour-un-topic" aria-hidden="true"><span class="octicon octicon-link"></span></a>Récupération de la configuration du cluster pour un topic</h3>

<p>Toute la configuration du cluster est mise à jour par Kafka dans Zookeeper. Pour pouvoir consommer des messages, il faut récupérer dans les metadata du topic le nombre de partitions configurés. On rappelle qu'un topic n'est qu'un ensemble de partition, chaque partition étant une "file" de messages persistante.</p>

<p>Il faut:</p>

<ul>
<li>créer un client Zookeeper</li>
<li>
<p>Chercher dans kafka.admin.AdminUtils la bonne méthode</p>

<p>// Réponse
val topicMetadata = AdminUtils.fetchTopicMetadataFromZk(topic, zkClient)</p>

<h3>
<a id="se-connecter-à-une-partition" class="anchor" href="#se-connecter-%C3%A0-une-partition" aria-hidden="true"><span class="octicon octicon-link"></span></a>Se connecter à une partition</h3>

<p>Il existe à un instant au plus 1 noeud Kafka leader pour une partition d'un topic donné. 
Pour faire simple, nous allons nous connecter à toutes les partitions du topic en une fois. Il faudra donc faire une boucle sur la liste des partitions que vous avez récupérer précédemment.</p>
</li>
</ul>

<p>Il faut: </p>

<ul>
<li>fouiller dans la réponse précédente pour trouver chaque leader de chaque partition. </li>
<li>
<p>se connecter au broker en instantiant un kafka.consumer.SimpleConsumer par partition.</p>

<p>// Réponse
val partitionsBroker: Map[Int, Option[Broker]] = topicMetadata.partitionsMetadata.groupBy(<em>.partitionId).toMap.mapValues(</em>.head.leader)</p>

<p>val partitionsConsumer: Map[Int, Option[SimpleConsumer]] = partitionsBroker.mapValues{optionalBroker =&gt; 
    optionalBroker.map{leader =&gt; new SimpleConsumer(leader.host, leader.port, 10000, 64000, "aCLientId")}
}</p>
</li>
</ul>

<h3>
<a id="trouver-loffset-de-démarrage-de-consommation" class="anchor" href="#trouver-loffset-de-d%C3%A9marrage-de-consommation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Trouver l'offset de démarrage de consommation</h3>

<p>Une partition est un journal en ajout seulement. Chaque message possède un numéro unique au sein d'une même partition. Cet identifiant, issu d'un compteur monotonique (strictement croissant), est nommé offset. 
Pour chaque requête de données à Kafka, on lui précise le nombre de messages que l'on veut recevoir, et depuis quelle position, offset.</p>

<p>Il faut: </p>

<pre><code>* trouver sur SimpleConsumer une méthode nous permettant de trouver l'identifiant du premier offset connu de chaque partition.

//Réponse
consumer.earliestOrLatestOffset(topicAndPartition, OffsetRequest.EarliestTime, Request.OrdinaryConsumerId)  
</code></pre>

<p>NB: on pourrait aussi lancer le consommateur depuis la fin courante de la file. Ainsi, le consommateur ne recevrait de messages que lorsqu'un nouveau serait posté.</p>

<h3>
<a id="faire-une-requête-de-données" class="anchor" href="#faire-une-requ%C3%AAte-de-donn%C3%A9es" aria-hidden="true"><span class="octicon octicon-link"></span></a>Faire une requête de données</h3>

<p>Maintenant que nous avons la connexion au leader et l'offset à demander, il n'y a plus qu'à récupérer les infos. Dans Kafka, on ne demande pas N messages. On demande une taille à récupérer. Dans la réponse, nous aurons ensuite un itérateur permettant de parcourir chaque message reçu. Il est donc <strong>important</strong> de connaître la taille des messages que l'on manipule. Cela semble bizarre au début mais cela se révèle être un atout majeur en terme de performance. En effet, toutes les I/O se mesurent en Bytes, network, buffer, disque... en ne manipulant que des tailles en bytes, il est ainsi d'être le plus précis possible pour le tuning de performance.</p>

<p>Il faut</p>

<pre><code>* créer une FetchRequest grâce au FetchRequestBuilder. 
* l'exécuter avec le SimpleConsumer
* itérer sur l'Iterator de MessageSet 

//Réponse
val request = new FetchRequestBuilder()
    .clientId(groupId)
    .addFetch(topic, partitionId, nextOffsetToFetch, maxMessageSize * count)
    .maxWait(fetchTimeout)
    .build()

val fetchReply = consumer.fetch(request)
</code></pre>

<p>NB: il est possible que Kafka vous envoie des messages un peu avant l'offset qui est demandé (pour des raisons d'optimisation). Si le côté transactionnel est important pour vous, pensez à filtrer sur les offsets des messages reçus.   </p>

<h3>
<a id="commit" class="anchor" href="#commit" aria-hidden="true"><span class="octicon octicon-link"></span></a>Commit</h3>

<p>Vous l'aurez ainsi remarqué, c'est le consommateur qui a la responsabilité de maintenir l'offset de lecture. Le broker Kafka ne sait pas à priori qui a déjà consommé quoi.
Il existe deux façons proposées par Kafka pour maintenir cette information, mais vous pouvez utiliser la votre. Il suffit juste de maintenir quelque part ce fameux offset de consommation.
Initialement, Kafka stockait les offsets dans Zookeeper. Cette solution fortement cohérente en système distribué s'est avéré trop peu performante. 
La seconde solution proposée par Kafka est de stocké lui même l'offset dans un topic maintenu par le cluster. Il existe un noeud particulier dans le cluster qui joue le rôle du coordinateur à qui on peut demander les offsets et de "commiter" un offset pour un groupe de consommateurs, topic et partition.</p>

<p>Pour trouver ce coordinateur</p>

<p>Il faut:</p>

<pre><code>* boucler sur la liste des brokers et s'arrêter au premier qui fonctionne (ou recommencer jusqu'à ce que cela fonctionne)
* créer un blockingChannel sur un broker
    val channel = new BlockingChannel(host, port, bufferSize, bufferSize, socketTimeout)
    channel.connect()
* Faire une requête ConsumerMetadataRequest 
    channel.send(new ConsumerMetadataRequest(groupId))
    val reply = ConsumerMetadataResponse.readFrom(channel.receive().buffer)
* S'il existe un coordinateur, il faut s'y connecter
* Faire un commit 
    val request = OffsetCommitRequest(
      groupId,
      Map(topicAndPartition -&gt; OffsetAndMetadata(offset)),
      versionId = 1
    )

    println(s"Committing offset &lt;$offset&gt; to partition &lt;$partition&gt;:&lt;$groupId&gt;")
    val reply = Try {
      channel.send(request)
      OffsetCommitResponse.readFrom(channel.receive().buffer)
    }

    reply.map(_.commitStatus(topicAndPartition)).filter(_ == NoError)
</code></pre>

<p>Pour lire cette valeur et ainsi recommencer à lire depuis le dernier offset connu, il faut :</p>

<pre><code>* sur le channel du coordinateur, faire une requête OffsetFetchRequest
    val request = OffsetFetchRequest(groupId, List(topicAndPartition))
    channel.send(request)
    OffsetFetchResponse.readFrom(channel.receive().buffer)
</code></pre>

<p>Vous pouvez ainsi récupérer le dernier offset connu, à la prochaine requête, vous pourez utiliser cette valuer.</p>

<h2>
<a id="et-ce-nest-pas-fini" class="anchor" href="#et-ce-nest-pas-fini" aria-hidden="true"><span class="octicon octicon-link"></span></a>Et ce n'est pas fini!</h2>

<p>Il manque encore plein de choses dans cette implem. Le cluster est dynamique, le coordinateur peut changer de noeud, les partitions peuvent être réassignées sur un autre noeud. Il faut</p>

<ul>
<li>Écouter les événements depuis ZK pour suivre les assignements des partitions</li>
<li>Réessayer plusieurs fois certaines action quand le cluster n'est pas stable (en phase de transition)</li>
<li>Il se peut que'offset commité n'existe plus dans Kafka, il faut ainsi s'assurer qu'il existe supérieur au premier offset connu...</li>
</ul>
        </section>

        <aside id="sidebar">
          <a href="https://github.com/mblanc/xke-kafka/zipball/master" class="button">
            <small>Download</small>
            .zip file
          </a>
          <a href="https://github.com/mblanc/xke-kafka/tarball/master" class="button">
            <small>Download</small>
            .tar.gz file
          </a>

          <p class="repo-owner"><a href="https://github.com/mblanc/xke-kafka"></a> is maintained by <a href="https://github.com/mblanc">mblanc</a>.</p>

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the Architect theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>

  
  </body>
</html>
